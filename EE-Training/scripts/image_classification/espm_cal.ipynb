{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6daf92",
   "metadata": {},
   "source": [
    "# ESPM: Eco-Sustainable Performance Metric "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab79c48",
   "metadata": {},
   "source": [
    "# FLOPS and Model Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c3277",
   "metadata": {},
   "source": [
    "## Calculate the FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating convnext_tiny...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::gelu encountered 18 time(s)\n",
      "Unsupported operator aten::mul encountered 18 time(s)\n",
      "Unsupported operator aten::add encountered 18 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating efficientnet_b0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 49 time(s)\n",
      "Unsupported operator aten::mean encountered 16 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 16 time(s)\n",
      "Unsupported operator aten::mul encountered 16 time(s)\n",
      "Unsupported operator aten::add encountered 9 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating efficientnet_b3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 78 time(s)\n",
      "Unsupported operator aten::mean encountered 26 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 26 time(s)\n",
      "Unsupported operator aten::mul encountered 26 time(s)\n",
      "Unsupported operator aten::add encountered 19 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating efficientnetv2_s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::silu_ encountered 102 time(s)\n",
      "Unsupported operator aten::add encountered 35 time(s)\n",
      "Unsupported operator aten::mean encountered 30 time(s)\n",
      "Unsupported operator aten::sigmoid encountered 30 time(s)\n",
      "Unsupported operator aten::mul encountered 30 time(s)\n",
      "Unsupported operator aten::hardtanh_ encountered 35 time(s)\n",
      "Unsupported operator aten::add encountered 10 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating mobilenetv2_100...\n",
      "üîç Evaluating mobilenetv3_large_100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::hardswish_ encountered 21 time(s)\n",
      "Unsupported operator aten::add encountered 10 time(s)\n",
      "Unsupported operator aten::mean encountered 8 time(s)\n",
      "Unsupported operator aten::hardsigmoid encountered 8 time(s)\n",
      "Unsupported operator aten::mul encountered 8 time(s)\n",
      "Unsupported operator aten::hardswish_ encountered 19 time(s)\n",
      "Unsupported operator aten::mean encountered 9 time(s)\n",
      "Unsupported operator aten::hardsigmoid encountered 9 time(s)\n",
      "Unsupported operator aten::mul encountered 9 time(s)\n",
      "Unsupported operator aten::add encountered 6 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating mobilenetv3_small_100...\n",
      "üîç Evaluating resnet101...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Unsupported operator aten::add_ encountered 33 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating resnet152...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Unsupported operator aten::add_ encountered 50 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Unsupported operator aten::add_ encountered 8 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating resnet18...\n",
      "üîç Evaluating resnet34...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Unsupported operator aten::add_ encountered 16 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating resnet50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Unsupported operator aten::add_ encountered 16 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating deit_base_patch16_224...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add encountered 25 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 12 time(s)\n",
      "Unsupported operator aten::gelu encountered 12 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "blocks.0.attn.attn_drop, blocks.1.attn.attn_drop, blocks.10.attn.attn_drop, blocks.11.attn.attn_drop, blocks.2.attn.attn_drop, blocks.3.attn.attn_drop, blocks.4.attn.attn_drop, blocks.5.attn.attn_drop, blocks.6.attn.attn_drop, blocks.7.attn.attn_drop, blocks.8.attn.attn_drop, blocks.9.attn.attn_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluating vit_base_patch16_224...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add encountered 25 time(s)\n",
      "Unsupported operator aten::scaled_dot_product_attention encountered 12 time(s)\n",
      "Unsupported operator aten::gelu encountered 12 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "blocks.0.attn.attn_drop, blocks.1.attn.attn_drop, blocks.10.attn.attn_drop, blocks.11.attn.attn_drop, blocks.2.attn.attn_drop, blocks.3.attn.attn_drop, blocks.4.attn.attn_drop, blocks.5.attn.attn_drop, blocks.6.attn.attn_drop, blocks.7.attn.attn_drop, blocks.8.attn.attn_drop, blocks.9.attn.attn_drop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved to model_flops_params.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from timm import create_model\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "import pandas as pd\n",
    "\n",
    "# Define models and input sizes\n",
    "model_inputs = {\n",
    "    \"convnext_tiny\": (3, 32, 32),\n",
    "    \"efficientnet_b0\": (3, 32, 32),\n",
    "    \"efficientnet_b3\": (3, 32, 32),\n",
    "    \"efficientnetv2_s\": (3, 32, 32),\n",
    "    \"mobilenetv2_100\": (3, 32, 32),\n",
    "    \"mobilenetv3_large_100\": (3, 32, 32),\n",
    "    \"mobilenetv3_small_100\": (3, 32, 32),\n",
    "    \"resnet101\": (3, 32, 32),\n",
    "    \"resnet152\": (3, 32, 32),\n",
    "    \"resnet18\": (3, 32, 32),\n",
    "    \"resnet34\": (3, 32, 32),\n",
    "    \"resnet50\": (3, 32, 32),\n",
    "    \"deit_base_patch16_224\": (3, 224, 224),\n",
    "    \"vit_base_patch16_224\": (3, 224, 224),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for model_name, input_shape in model_inputs.items():\n",
    "    try:\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        model = create_model(model_name, pretrained=False).to(device).eval()\n",
    "        input_tensor = torch.randn(1, *input_shape).to(device)\n",
    "\n",
    "        # FLOPs calculation\n",
    "        flops = FlopCountAnalysis(model, input_tensor)\n",
    "        forward_flops = flops.total() / 1e9  # Convert to GFLOPs\n",
    "        training_flops = forward_flops * 2   # Estimated training FLOPs (forward + backward only)\n",
    "\n",
    "        # Params calculation\n",
    "        num_params = sum(p.numel() for p in model.parameters()) / 1e6  # Convert to Millions\n",
    "\n",
    "        results.append((model_name, round(forward_flops, 3), round(training_flops, 3), round(num_params, 2)))\n",
    "\n",
    "    except Exception as e:\n",
    "        results.append((model_name, \"‚ùå Error\", \"‚ùå Error\", str(e)))\n",
    "\n",
    "# Save to CSV\n",
    "# Flops in GFLOPs, Params in Millions\n",
    "df = pd.DataFrame(results, columns=[\"model\", \"forward_flops\", \"training_flops\", \"params\"])\n",
    "df.to_csv(\"/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/model_flops_params.csv\", index=False)\n",
    "print(\"‚úÖ Saved to model_flops_params.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d103a7",
   "metadata": {},
   "source": [
    "## Add Flops and Params to training_energy.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FLOPs and params added without duplicating 'model' in training_energy.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both CSVs # Change the path to your actual file paths\n",
    "flops_df = pd.read_csv(\"/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/model_flops_params.csv\")\n",
    "energy_df = pd.read_csv(\"/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv\")\n",
    "\n",
    "# Select only the columns to append (exclude duplicate 'model')\n",
    "flops_data = flops_df.set_index(\"model\")[[\"forward_flops\", \"training_flops\", \"params\"]]\n",
    "\n",
    "# Match by model and append columns\n",
    "for col in flops_data.columns:\n",
    "    energy_df[col] = energy_df[\"model\"].map(flops_data[col])\n",
    "\n",
    "# Save result\n",
    "energy_df.to_csv(\"/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv\", index=False)\n",
    "\n",
    "print(\"FLOPs and params added in training_energy.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36fc42",
   "metadata": {},
   "source": [
    "## Check Duplicate Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b599abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 duplicate experiment_name entries:\n",
      "\n",
      "Maximum value of energy_consumed: 1.870135952871025\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your file\n",
    "file_path = '/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv'\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Identify duplicate experiment names\n",
    "duplicate_experiments = df[df.duplicated(subset=[\"experiment_name\"], keep=False)]\n",
    "\n",
    "# Extract just the duplicated names\n",
    "duplicate_names = duplicate_experiments[\"experiment_name\"].dropna().unique()\n",
    "\n",
    "# Print result\n",
    "print(f\"Found {len(duplicate_names)} duplicate experiment_name entries:\")\n",
    "for name in duplicate_names:\n",
    "    print(name)\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Print maximum value of energy_consumed\n",
    "max_energy = df['energy_consumed'].max()\n",
    "print(f\"\\nMaximum value of energy_consumed: {max_energy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334eb60",
   "metadata": {},
   "source": [
    "## Energy Consumption and Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76cc2156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Energy Consumption:\n",
      "    Metric                          Experiment Name  Energy (kWh)  Accuracy (%)\n",
      "Min Energy mobilenetv3_small_100_cifar10_50ep_bs128        0.1030         90.05\n",
      "Max Energy             resnet152_cifar10_100ep_bs32        1.8701         94.20\n",
      "\n",
      "Average Energy (kWh): 0.6987\n",
      "\n",
      "‚è±Ô∏è Duration:\n",
      "      Metric                          Experiment Name  Duration (hrs)  Accuracy (%)\n",
      "Min Duration mobilenetv3_small_100_cifar10_50ep_bs128            0.33         90.05\n",
      "Max Duration             resnet152_cifar10_100ep_bs32            4.47         94.20\n",
      "\n",
      "Average Duration (hrs): 1.69\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "file_path = '/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert duration from seconds to hours\n",
    "df['duration_hours'] = df['duration'] / 3600\n",
    "\n",
    "# --- Energy Stats ---\n",
    "min_energy_row = df.loc[df['energy_consumed'].idxmin()]\n",
    "max_energy_row = df.loc[df['energy_consumed'].idxmax()]\n",
    "\n",
    "energy_data = {\n",
    "    \"Metric\": [\"Min Energy\", \"Max Energy\"],\n",
    "    \"Experiment Name\": [min_energy_row['experiment_name'], max_energy_row['experiment_name']],\n",
    "    \"Energy (kWh)\": [round(min_energy_row['energy_consumed'], 4), round(max_energy_row['energy_consumed'], 4)],\n",
    "    \"Accuracy (%)\": [round(min_energy_row['eval_top1'], 2), round(max_energy_row['eval_top1'], 2)]\n",
    "}\n",
    "energy_df = pd.DataFrame(energy_data)\n",
    "\n",
    "# --- Duration Stats ---\n",
    "min_duration_row = df.loc[df['duration_hours'].idxmin()]\n",
    "max_duration_row = df.loc[df['duration_hours'].idxmax()]\n",
    "\n",
    "duration_data = {\n",
    "    \"Metric\": [\"Min Duration\", \"Max Duration\"],\n",
    "    \"Experiment Name\": [min_duration_row['experiment_name'], max_duration_row['experiment_name']],\n",
    "    \"Duration (hrs)\": [round(min_duration_row['duration_hours'], 2), round(max_duration_row['duration_hours'], 2)],\n",
    "    \"Accuracy (%)\": [round(min_duration_row['eval_top1'], 2), round(max_duration_row['eval_top1'], 2)]\n",
    "}\n",
    "duration_df = pd.DataFrame(duration_data)\n",
    "\n",
    "# --- Averages ---\n",
    "avg_energy = round(df['energy_consumed'].mean(), 4)\n",
    "avg_duration = round(df['duration_hours'].mean(), 2)\n",
    "\n",
    "# --- Print Results ---\n",
    "print(\"üìä Energy Consumption:\")\n",
    "print(energy_df.to_string(index=False))\n",
    "print(f\"\\nAverage Energy (kWh): {avg_energy:.4f}\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è Duration:\")\n",
    "print(duration_df.to_string(index=False))\n",
    "print(f\"\\nAverage Duration (hrs): {avg_duration:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad209f9e",
   "metadata": {},
   "source": [
    "# Sustainable-Accuracy Metric (SAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ae6e2",
   "metadata": {},
   "source": [
    "![SAM](../../Docs/img/sam.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab622a50",
   "metadata": {},
   "source": [
    "## Calculate SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f2e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SAM values calculated and saved to the CSV file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file from the specified path\n",
    "file_path = '/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define constants\n",
    "alpha = 5\n",
    "beta = 5\n",
    "\n",
    "# Normalize accuracy (0‚Äì100 ‚Üí 0‚Äì1)\n",
    "accuracy_normalized = df['eval_top1'] / 100\n",
    "\n",
    "# Calculate SAM\n",
    "df['SAM'] = beta * (accuracy_normalized ** alpha) / np.log10(df['energy_consumed'])\n",
    "\n",
    "# Save the updated DataFrame back to the same file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"SAM values calculated and saved to the CSV file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e84ee",
   "metadata": {},
   "source": [
    "### Min and Max SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018f1ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîΩ Minimum SAM:\n",
      "   Experiment Name  : efficientnet_b3_cifar10_75ep_bs64\n",
      "   SAM Value        : -57037.3378\n",
      "   Accuracy (Top-1) : 94.89%\n",
      "   Energy (kWh)     : 0.9998\n",
      "   log10(Energy)    : -0.00006744\n",
      "\n",
      "üîº Maximum SAM:\n",
      "   Experiment Name  : resnet101_cifar10_75ep_bs32\n",
      "   SAM Value        : 17563.7429\n",
      "   Accuracy (Top-1) : 93.56%\n",
      "   Energy (kWh)     : 1.0005\n",
      "   log10(Energy)    : 0.00020408\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV\n",
    "file_path = '/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Get row with minimum SAM\n",
    "min_sam_row = df.loc[df['SAM'].idxmin()]\n",
    "# Get row with maximum SAM\n",
    "max_sam_row = df.loc[df['SAM'].idxmax()]\n",
    "\n",
    "# Calculate log10 of energy\n",
    "min_log_energy = np.log10(min_sam_row['energy_consumed'])\n",
    "max_log_energy = np.log10(max_sam_row['energy_consumed'])\n",
    "\n",
    "# Print results\n",
    "print(\"üîΩ Minimum SAM:\")\n",
    "print(f\"   Experiment Name  : {min_sam_row['experiment_name']}\")\n",
    "print(f\"   SAM Value        : {min_sam_row['SAM']:.4f}\")\n",
    "print(f\"   Accuracy (Top-1) : {min_sam_row['eval_top1']}%\")\n",
    "print(f\"   Energy (kWh)     : {min_sam_row['energy_consumed']:.4f}\")\n",
    "print(f\"   log10(Energy)    : {min_log_energy:.8f}\\n\")\n",
    "\n",
    "print(\"üîº Maximum SAM:\")\n",
    "print(f\"   Experiment Name  : {max_sam_row['experiment_name']}\")\n",
    "print(f\"   SAM Value        : {max_sam_row['SAM']:.4f}\")\n",
    "print(f\"   Accuracy (Top-1) : {max_sam_row['eval_top1']}%\")\n",
    "print(f\"   Energy (kWh)     : {max_sam_row['energy_consumed']:.4f}\")\n",
    "print(f\"   log10(Energy)    : {max_log_energy:.8f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b83de7",
   "metadata": {},
   "source": [
    "## Calculate SAM (Watt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c03bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SAM_watt values calculated using Wh and saved to the CSV file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define constants\n",
    "alpha = 5\n",
    "beta = 5\n",
    "\n",
    "# Normalize accuracy (0‚Äì100 ‚Üí 0‚Äì1)\n",
    "accuracy_normalized = df['eval_top1'] / 100\n",
    "\n",
    "# Convert energy from kWh to Wh\n",
    "energy_wh = df['energy_consumed'] * 1000\n",
    "\n",
    "# Calculate SAM using Wh\n",
    "df['SAM_watt'] = beta * (accuracy_normalized ** alpha) / np.log10(energy_wh)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"SAM_watt values calculated using Wh and saved to the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebe6ddc",
   "metadata": {},
   "source": [
    "### Min and Max SAM Watt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9758a801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîΩ Minimum SAM:\n",
      "   SAM Value        : 0.0007\n",
      "   Accuracy (Top-1) : 20.9%\n",
      "   Energy (kWh)     : 0.4829\n",
      "\n",
      "üîº Maximum SAM:\n",
      "   SAM Value        : 1.5311\n",
      "   Accuracy (Top-1) : 92.22%\n",
      "   Energy (kWh)     : 0.1507\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "file_path = '/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Get row with minimum SAM\n",
    "min_sam_row = df.loc[df['SAM_watt'].idxmin()]\n",
    "# Get row with maximum SAM\n",
    "max_sam_row = df.loc[df['SAM_watt'].idxmax()]\n",
    "\n",
    "# Print results\n",
    "print(\"üîΩ Minimum SAM:\")\n",
    "print(f\"   SAM Value        : {min_sam_row['SAM_watt']:.4f}\")\n",
    "print(f\"   Accuracy (Top-1) : {min_sam_row['eval_top1']}%\")\n",
    "print(f\"   Energy (kWh)     : {min_sam_row['energy_consumed']:.4f}\\n\")\n",
    "\n",
    "print(\"üîº Maximum SAM:\")\n",
    "print(f\"   SAM Value        : {max_sam_row['SAM_watt']:.4f}\")\n",
    "print(f\"   Accuracy (Top-1) : {max_sam_row['eval_top1']}%\")\n",
    "print(f\"   Energy (kWh)     : {max_sam_row['energy_consumed']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5572f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîΩ Top 5 Minimum SAM_watt Entries:\n",
      "\n",
      "                  Experiment Name  Accuracy (Top-1)  Energy (kWh)  SAM_watt  training_flops  params  throughput\n",
      " convnext_tiny_cifar100_50ep_bs32             20.90      0.482916  0.000743           0.184   28.59  594.698287\n",
      " convnext_tiny_cifar100_50ep_bs64             22.00      0.434484  0.000977           0.184   28.59  662.049426\n",
      "convnext_tiny_cifar100_50ep_bs128             24.76      0.410943  0.001780           0.184   28.59  698.150194\n",
      " convnext_tiny_cifar100_75ep_bs64             28.03      0.654292  0.003072           0.184   28.59  661.606356\n",
      " convnext_tiny_cifar100_75ep_bs32             30.39      0.723765  0.004532           0.184   28.59  601.411174\n",
      "\n",
      "üîº Top 5 Maximum SAM_watt Entries:\n",
      "\n",
      "                         Experiment Name  Accuracy (Top-1)  Energy (kWh)  SAM_watt  training_flops  params  throughput\n",
      "mobilenetv3_large_100_cifar10_50ep_bs128             92.22      0.150714  1.531113           0.017    5.48 1830.958355\n",
      " mobilenetv3_large_100_cifar10_50ep_bs64             92.47      0.165136  1.524206           0.017    5.48 1710.190904\n",
      "mobilenetv3_large_100_cifar10_75ep_bs128             93.49      0.226430  1.516412           0.017    5.48 1834.198445\n",
      "      efficientnet_b0_cifar10_50ep_bs128             93.06      0.220087  1.489664           0.020    5.29 1287.836741\n",
      "       efficientnet_b0_cifar10_50ep_bs64             93.26      0.233329  1.489605           0.020    5.29 1218.845217\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "file_path = '/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select relevant columns\n",
    "columns = ['experiment_name', 'eval_top1', 'energy_consumed', 'SAM_watt', 'training_flops', 'params', 'throughput']\n",
    "\n",
    "# Get top 5 min and max SAM_watt entries\n",
    "min_sam_table = df.nsmallest(5, 'SAM_watt')[columns].copy()\n",
    "max_sam_table = df.nlargest(5, 'SAM_watt')[columns].copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "min_sam_table.columns = ['Experiment Name', 'Accuracy (Top-1)', 'Energy (kWh)', 'SAM_watt' , 'training_flops', 'params', 'throughput']\n",
    "max_sam_table.columns = ['Experiment Name', 'Accuracy (Top-1)', 'Energy (kWh)', 'SAM_watt' , 'training_flops', 'params', 'throughput']\n",
    "\n",
    "# Print the tables\n",
    "print(\"üîΩ Top 5 Minimum SAM_watt Entries:\\n\")\n",
    "print(min_sam_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nüîº Top 5 Maximum SAM_watt Entries:\\n\")\n",
    "print(max_sam_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef604f0",
   "metadata": {},
   "source": [
    "# Eco-Sustainable Performance Metric (ESPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef05069",
   "metadata": {},
   "source": [
    "![ESPM](../../Docs/img/espm_v1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bac6fd",
   "metadata": {},
   "source": [
    "## Cal ESPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77465b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ESPM, EF, and Throughput calculated using 400 gCO‚ÇÇ/kWh (converted to kg) and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Constants\n",
    "alpha = 5\n",
    "num_training_samples = 50000  # CIFAR-10 or CIFAR-100\n",
    "carbon_intensity_grams = 400  # gCO‚ÇÇ/kWh\n",
    "\n",
    "# Normalize accuracy (0‚Äì100 ‚Üí 0‚Äì1)\n",
    "accuracy_normalized = df['eval_top1'] / 100\n",
    "\n",
    "# Throughput = total samples / duration\n",
    "df['throughput'] = (num_training_samples * df['epochs']) / df['duration']\n",
    "\n",
    "# Convert GFLOPs ‚Üí FLOPs and Million Params ‚Üí actual count\n",
    "training_flops_actual = df['training_flops'] * 1e9\n",
    "params_actual = df['params'] * 1e6\n",
    "\n",
    "# Efficiency Factor (EF)\n",
    "df['ef'] = df['throughput'] / np.log10(training_flops_actual * params_actual)\n",
    "\n",
    "\n",
    "# ESPM using converted carbon intensity\n",
    "df['espm'] = (accuracy_normalized ** alpha * df['ef']) / np.log10(\n",
    "    df['energy_consumed'] * df['pue'] * carbon_intensity_grams\n",
    ")\n",
    "\n",
    "# Save updated file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"‚úÖ ESPM, EF, and Throughput calculated using 400 gCO‚ÇÇ/kWh (converted to kg) and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a6382",
   "metadata": {},
   "source": [
    "## Min Max ESPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47bc1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîΩ Top 5 Minimum ESPM Entries:\n",
      "\n",
      "                  Experiment Name  Accuracy (Top-1)  Energy (kWh)     ESPM  training_flops  params  throughput\n",
      " convnext_tiny_cifar100_50ep_bs32             20.90      0.482916 0.006599           0.184   28.59  594.698287\n",
      " convnext_tiny_cifar100_50ep_bs64             22.00      0.434484 0.009689           0.184   28.59  662.049426\n",
      "convnext_tiny_cifar100_50ep_bs128             24.76      0.410943 0.018650           0.184   28.59  698.150194\n",
      " convnext_tiny_cifar100_75ep_bs64             28.03      0.654292 0.030117           0.184   28.59  661.606356\n",
      " convnext_tiny_cifar100_75ep_bs32             30.39      0.723765 0.040282           0.184   28.59  601.411174\n",
      "\n",
      "üîº Top 5 Maximum ESPM Entries:\n",
      "\n",
      "                          Experiment Name  Accuracy (Top-1)  Energy (kWh)      ESPM  training_flops  params  throughput\n",
      " mobilenetv3_small_100_cifar10_50ep_bs128             90.05      0.103035 59.031464           0.006    2.54 2122.578709\n",
      "  mobilenetv3_small_100_cifar10_50ep_bs64             89.81      0.104937 57.678041           0.006    2.54 2112.108355\n",
      " mobilenetv3_small_100_cifar10_75ep_bs128             91.28      0.156359 56.417186           0.006    2.54 2108.129272\n",
      "  mobilenetv3_small_100_cifar10_75ep_bs64             91.35      0.159677 56.014155           0.006    2.54 2095.648592\n",
      "mobilenetv3_small_100_cifar10_100ep_bs128             92.18      0.209120 55.264220           0.006    2.54 2104.410909\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "file_path = '/home/escade/ESCADE/code/git/pytorch-image-models/EE-Training/Dataset/image_classification/training_energy.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select relevant columns\n",
    "columns = ['experiment_name', 'eval_top1', 'energy_consumed', 'espm', 'training_flops', 'params', 'throughput']\n",
    "\n",
    "# Get top 5 min and max SAM_watt entries\n",
    "min_sam_table = df.nsmallest(5, 'espm')[columns].copy()\n",
    "max_sam_table = df.nlargest(5, 'espm')[columns].copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "min_sam_table.columns = ['Experiment Name', 'Accuracy (Top-1)', 'Energy (kWh)', 'ESPM', 'training_flops', 'params', 'throughput']\n",
    "max_sam_table.columns = ['Experiment Name', 'Accuracy (Top-1)', 'Energy (kWh)', 'ESPM', 'training_flops', 'params', 'throughput']\n",
    "\n",
    "# Print the tables\n",
    "print(\"üîΩ Top 5 Minimum ESPM Entries:\\n\")\n",
    "print(min_sam_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nüîº Top 5 Maximum ESPM Entries:\\n\")\n",
    "print(max_sam_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e63e9f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "escade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
